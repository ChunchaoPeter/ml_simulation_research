{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filter Demo - Range-Bearing Tracking\n",
    "\n",
    "Demonstrates the Particle Filter implementation from `pf_code.py` (Algorithm 3, Notes 9).\n",
    "\n",
    "**Model:**\n",
    "- State: Linear dynamics with constant velocity\n",
    "- Observation: Nonlinear range-bearing measurements\n",
    "- Filter: Bootstrap particle filter with prior proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pf import ParticleFilter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"TensorFlow Probability version: {tfp.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Range-Bearing Particle Filter Model\n",
    "\n",
    "Define model functions for range-bearing tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangeBearingParticleFilter:\n",
    "    \"\"\"Particle Filter Model for Range-Bearing Tracking.\"\"\"\n",
    "    \n",
    "    def __init__(self, A, G, Q, R, num_particles=100, dtype=tf.float64):\n",
    "        self.A = tf.constant(A, dtype=dtype)\n",
    "        self.G = tf.constant(G, dtype=dtype)\n",
    "        self.Q = tf.constant(Q, dtype=dtype)\n",
    "        self.R = tf.constant(R, dtype=dtype)\n",
    "        self.num_particles = num_particles\n",
    "        self.dtype = dtype\n",
    "        self.R_inv = tf.linalg.inv(R)\n",
    "    \n",
    "    def state_transition(self, x, u=None):\n",
    "        \"\"\"State transition: x_t = A @ x_{t-1}\"\"\"\n",
    "        return tf.matmul(self.A, x)\n",
    "    \n",
    "    def observation_function(self, x):\n",
    "        \"\"\"Observation: h(x) = [range, bearing]\"\"\"\n",
    "        range_pred = tf.sqrt(x[0, 0]**2 + x[1, 0]**2)\n",
    "        bearing_pred = tf.atan2(x[1, 0], x[0, 0])\n",
    "        return tf.reshape([range_pred, bearing_pred], (2, 1))\n",
    "    \n",
    "    def likelihood_function(self, z, x):\n",
    "        \"\"\"Likelihood: p(z|x) = N(z; h(x), R)\"\"\"\n",
    "        z_pred = self.observation_function(x)\n",
    "        v = z - z_pred\n",
    "        exponent = -0.5 * tf.matmul(tf.transpose(v), tf.matmul(self.R_inv, v))[0, 0]\n",
    "        return tf.exp(exponent)\n",
    "    \n",
    "    def process_noise_sampler(self, num_samples):\n",
    "        \"\"\"Sample process noise: G @ W where W ~ N(0, Q)\"\"\"\n",
    "        noise_dist = tfd.MultivariateNormalTriL(\n",
    "            loc=tf.zeros(2, dtype=self.dtype),\n",
    "            scale_tril=tf.linalg.cholesky(self.Q)\n",
    "        )\n",
    "        W = noise_dist.sample(num_samples)\n",
    "        return tf.matmul(self.G, tf.transpose(W))\n",
    "    \n",
    "    def initial_sampler(self, x0, P0):\n",
    "        \"\"\"Create initial state sampler\"\"\"\n",
    "        def sampler(num_samples):\n",
    "            x0_flat = tf.reshape(x0, [-1])\n",
    "            initial_dist = tfd.MultivariateNormalTriL(\n",
    "                loc=x0_flat,\n",
    "                scale_tril=tf.linalg.cholesky(P0)\n",
    "            )\n",
    "            return tf.transpose(initial_dist.sample(num_samples))\n",
    "        return sampler\n",
    "\n",
    "\n",
    "def run_particle_filter(model, observations, x0, P0, return_details=False):\n",
    "    \"\"\"Run particle filter using the model.\"\"\"\n",
    "    observations = tf.constant(observations, dtype=model.dtype)\n",
    "    if observations.shape[0] > observations.shape[1]:\n",
    "        observations = tf.transpose(observations)\n",
    "    \n",
    "    pf = ParticleFilter(\n",
    "        state_transition_fn=model.state_transition,\n",
    "        observation_fn=model.observation_function,\n",
    "        process_noise_sampler=model.process_noise_sampler,\n",
    "        observation_likelihood_fn=model.likelihood_function,\n",
    "        x0_sampler=model.initial_sampler(x0, P0),\n",
    "        num_particles=model.num_particles,\n",
    "        dtype=model.dtype\n",
    "    )\n",
    "    \n",
    "    return pf.filter(observations, return_details=return_details)\n",
    "\n",
    "\n",
    "print(\"✓ RangeBearingParticleFilter class defined\")\n",
    "print(\"✓ run_particle_filter function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observations\n",
    "T_values = tf.constant([5., 10., 15., 20., 25., 30., 35., 40., 45., 50., 55., 60., 65., 70., 75., 80., \n",
    "                        85., 90., 95., 100., 105., 110., 115., 120., 125., 130., 135., 140., 145., 150., \n",
    "                        155., 160., 165., 170., 175., 180., 185., 190., 195., 200.], dtype=tf.float64)\n",
    "\n",
    "Range = tf.constant([\n",
    "    27.942258, 27.963234, 27.204243, 26.540936, 26.135477, 24.921334, 26.008057, 23.451562,\n",
    "    23.475078, 22.859580, 22.441457, 20.646783, 21.282532, 21.026488, 21.922655, 23.111669,\n",
    "    24.607487, 26.674349, 27.889730, 29.995459, 31.511762, 31.999494, 32.519595, 33.830023,\n",
    "    33.801987, 34.345191, 34.878209, 35.858721, 37.624024, 39.121417, 40.449665, 40.245695,\n",
    "    40.242868, 41.246978, 41.759315, 41.612828, 42.370687, 43.895030, 45.125174, 48.508522\n",
    "], dtype=tf.float64)\n",
    "\n",
    "Theta = tf.constant([\n",
    "    0.817212, 0.844120, 0.870304, 0.939488, 0.977246, 1.009955, 1.095079, 1.123509,\n",
    "    1.195098, 1.317959, 1.404055, 1.569062, 1.679964, 1.751688, 1.908451, 2.032702,\n",
    "    2.144561, 2.159674, 2.172540, 2.231149, 2.217351, 2.157791, 2.140403, 2.165825,\n",
    "    2.121799, 2.082291, 2.126691, 2.102974, 2.034597, 2.031375, 2.024936, 2.053166,\n",
    "    2.010958, 1.983078, 2.000593, 2.042380, 2.023929, 2.044431, 2.006127, 1.991178\n",
    "], dtype=tf.float64)\n",
    "\n",
    "observations = tf.stack([Range, Theta], axis=1)  # (T, 2)\n",
    "\n",
    "# Convert observations to Cartesian\n",
    "obs_x = Range * tf.cos(Theta)\n",
    "obs_y = Range * tf.sin(Theta)\n",
    "\n",
    "# Model parameters\n",
    "T = 5  # Time step\n",
    "A = tf.constant([[1., 0., T, 0.], [0., 1., 0., T], [0., 0., 1., 0.], [0., 0., 0., 1.]], dtype=tf.float64)\n",
    "G = tf.constant([[0., 0.], [0., 0.], [T, 0.], [0., T]], dtype=tf.float64)\n",
    "Q = tf.constant([[0.001, 0.], [0., 0.001]], dtype=tf.float64)\n",
    "R = tf.constant([[0.25, 0.], [0., 5e-4]], dtype=tf.float64)\n",
    "x0 = tf.constant([20., 20., -0.2, 0.], dtype=tf.float64)\n",
    "P0 = tf.constant([[1.0, 0., 0., 0.], [0., 1.0, 0., 0.], [0., 0., 0.01, 0.], [0., 0., 0., 0.01]], dtype=tf.float64)\n",
    "\n",
    "print(f\"Loaded {len(T_values)} observations\")\n",
    "print(f\"Model: 4D state (x, y, vx, vy), 2D observation (range, bearing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Particle Filter (N=100)\n",
    "\n",
    "Shows **observation**, **prediction** (before measurement update), and **estimation** (after measurement update)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and run filter with diagnostics to get predictions\n",
    "pf_model = RangeBearingParticleFilter(A, G, Q, R, num_particles=100, dtype=tf.float64)\n",
    "filtered_states, predicted_states, particles_hist, weights_hist, ess_hist, ancestry_hist = \\\n",
    "    run_particle_filter(pf_model, observations, x0, P0, return_details=True)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "estimation = tf.transpose(filtered_states).numpy()  # (T+1, 4)\n",
    "prediction = tf.transpose(predicted_states).numpy()  # (T, 4)\n",
    "\n",
    "# Plot results with all three lines\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Trajectory plot\n",
    "ax = axes[0]\n",
    "# Observation (blue dashed)\n",
    "obs_x_with_init = np.concatenate([[x0[0].numpy()], obs_x.numpy()])\n",
    "obs_y_with_init = np.concatenate([[x0[1].numpy()], obs_y.numpy()])\n",
    "ax.plot(obs_x_with_init, obs_y_with_init, '--o', color='blue', label='Observation', \n",
    "        markersize=4, alpha=0.6, linewidth=1.5)\n",
    "\n",
    "# Prediction (green dashed)\n",
    "pred_x = np.concatenate([[x0[0].numpy()], prediction[:, 0]])\n",
    "pred_y = np.concatenate([[x0[1].numpy()], prediction[:, 1]])\n",
    "ax.plot(pred_x, pred_y, '--s', color='green', label='Prediction', \n",
    "        markersize=4, alpha=0.6, linewidth=1.5)\n",
    "\n",
    "# Estimation (red solid)\n",
    "ax.plot(estimation[:, 0], estimation[:, 1], '-^', color='red', label='Estimation', \n",
    "        markersize=4, alpha=0.8, linewidth=2)\n",
    "\n",
    "ax.scatter(x0[0].numpy(), x0[1].numpy(), color='black', s=100, marker='o', \n",
    "           label='Start', zorder=5, edgecolors='white', linewidths=1.5)\n",
    "ax.set_xlabel('X Position (m)', fontsize=11)\n",
    "ax.set_ylabel('Y Position (m)', fontsize=11)\n",
    "ax.set_title('Particle Filter Results (N=100)', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axis('equal')\n",
    "\n",
    "# Error plot\n",
    "ax = axes[1]\n",
    "obs_positions = tf.stack([obs_x, obs_y], axis=1).numpy()\n",
    "pred_errors = np.linalg.norm(prediction[:, :2] - obs_positions, axis=1)\n",
    "est_errors = np.linalg.norm(estimation[1:, :2] - obs_positions, axis=1)\n",
    "\n",
    "ax.plot(T_values.numpy(), pred_errors, '--', color='green', label=f'Prediction (RMSE={np.sqrt(np.mean(pred_errors**2)):.3f})', \n",
    "        linewidth=2, alpha=0.7)\n",
    "ax.plot(T_values.numpy(), est_errors, '-', color='red', label=f'Estimation (RMSE={np.sqrt(np.mean(est_errors**2)):.3f})', \n",
    "        linewidth=2, alpha=0.8)\n",
    "ax.set_xlabel('Time', fontsize=11)\n",
    "ax.set_ylabel('Position Error (m)', fontsize=11)\n",
    "ax.set_title('Position Error Over Time', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Results (N=100) ===\")\n",
    "print(f\"Prediction RMSE: {np.sqrt(np.mean(pred_errors**2)):.4f} m\")\n",
    "print(f\"Estimation RMSE: {np.sqrt(np.mean(est_errors**2)):.4f} m\")\n",
    "print(f\"Improvement: {(1 - np.sqrt(np.mean(est_errors**2)) / np.sqrt(np.mean(pred_errors**2))) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Particle Count Comparison\n",
    "\n",
    "Compare N=50, 100, and 500 particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different particle counts\n",
    "particle_counts = [50, 100, 500]\n",
    "results = {}\n",
    "\n",
    "for N in particle_counts:\n",
    "    model = RangeBearingParticleFilter(A, G, Q, R, num_particles=N, dtype=tf.float64)\n",
    "    filtered = run_particle_filter(model, observations, x0, P0, return_details=False)\n",
    "    est = tf.transpose(filtered).numpy()\n",
    "    errors = np.linalg.norm(est[1:, :2] - obs_positions, axis=1)\n",
    "    results[N] = {'estimation': est, 'errors': errors, 'rmse': np.sqrt(np.mean(errors**2))}\n",
    "    print(f\"N={N:3d}: RMSE = {results[N]['rmse']:.4f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['blue', 'red', 'orange']\n",
    "\n",
    "# Trajectory comparison\n",
    "ax = axes[0]\n",
    "ax.plot(obs_x_with_init, obs_y_with_init, 'k--o', label='Observation', alpha=0.4, markersize=3)\n",
    "for i, N in enumerate(particle_counts):\n",
    "    est = results[N]['estimation']\n",
    "    ax.plot(est[:, 0], est[:, 1], '-', color=colors[i], label=f'PF (N={N})', alpha=0.7, linewidth=2)\n",
    "ax.scatter(x0[0].numpy(), x0[1].numpy(), color='black', s=80, marker='o', zorder=5)\n",
    "ax.set_xlabel('X Position (m)')\n",
    "ax.set_ylabel('Y Position (m)')\n",
    "ax.set_title('Trajectory Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axis('equal')\n",
    "\n",
    "# Error comparison\n",
    "ax = axes[1]\n",
    "for i, N in enumerate(particle_counts):\n",
    "    ax.plot(T_values.numpy(), results[N]['errors'], '-', color=colors[i], \n",
    "            label=f'N={N} (RMSE={results[N][\"rmse\"]:.3f})', alpha=0.7, linewidth=2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Position Error (m)')\n",
    "ax.set_title('Error Over Time')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Diagnostics: ESS and Resampling\n",
    "\n",
    "Effective Sample Size (ESS) measures particle diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use diagnostics from N=100 run above\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ESS over time\n",
    "time_steps = np.concatenate([[0], T_values.numpy()])\n",
    "ax1.plot(time_steps, ess_hist.numpy(), 'b-o', linewidth=2, markersize=4)\n",
    "ax1.axhline(y=100, color='r', linestyle='--', label='N=100', alpha=0.6)\n",
    "ax1.axhline(y=50, color='orange', linestyle='--', label='N/2', alpha=0.6)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Effective Sample Size (ESS)')\n",
    "ax1.set_title('Particle Diversity Over Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Weight concentration\n",
    "max_weights = tf.reduce_max(weights_hist, axis=0).numpy()\n",
    "ax2.plot(time_steps, max_weights, 'g-o', linewidth=2, markersize=4)\n",
    "ax2.axhline(y=1/100, color='r', linestyle='--', label='Uniform (1/N)', alpha=0.6)\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Maximum Particle Weight')\n",
    "ax2.set_title('Weight Concentration')\n",
    "ax2.set_yscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean ESS: {tf.reduce_mean(ess_hist).numpy():.1f} / 100\")\n",
    "print(f\"Resampling events: {int(tf.reduce_sum(resample_hist).numpy())} / {len(T_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Results:**\n",
    "- Particle filter successfully tracks nonlinear range-bearing observations\n",
    "- Prediction vs Estimation: Measurement update reduces error by ~20-30%\n",
    "- Particle count: N=100 provides good accuracy/cost balance\n",
    "- ESS remains healthy (>50% of N) throughout tracking\n",
    "\n",
    "**Algorithm:** Bootstrap particle filter (Algorithm 3, Notes 9)\n",
    "- Prior proposal: q_{t|t-1} = f\n",
    "- Multinomial resampling maintains particle diversity\n",
    "- No Jacobians required (unlike EKF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ekf_ukf_pf_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

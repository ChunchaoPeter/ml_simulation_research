{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDH Filter: Function-Based Implementation\n",
    "\n",
    "This notebook implements the **Exact Daum-Huang (EDH)** filter using **pure functions** (no classes).\n",
    "\n",
    "Each function directly corresponds to specific lines in **Algorithm 1** from Ding & Coates (2012).\n",
    "\n",
    "## Algorithm 1: Original Exact Flow Daum-Huang Filter\n",
    "\n",
    "```\n",
    "Initialization:\n",
    "  1  Draw {x_0^i}_{i=1}^N from the prior p(x_0)\n",
    "  2  Set x̂_0 and m_0 as the mean; P_0 as the covariance matrix\n",
    "\n",
    "  3  for k = 1 to T do\n",
    "  4    Propagate particles x_{k-1}^i = f_k(x_{k-1}^i) + v_k\n",
    "  5    Calculate the mean value x̄_k\n",
    "  6    Apply UKF/EKF prediction:\n",
    "         (m_{k-1|k-1}, P_{k-1|k-1}) → (m_{k|k-1}, P_{k|k-1})\n",
    "  7    for j = 1, ..., N_λ do\n",
    "  8      Set λ = j∆λ\n",
    "  9      Calculate H_x by linearizing γ_k() at x̄_k\n",
    " 10      Calculate A and b from (8) and (9) using\n",
    "           P_{k|k-1}, x̄ and H_x\n",
    " 11      for i = 1, ..., N do\n",
    " 12        Evaluate dx_k^i/dλ for each particle from (7)\n",
    " 13        Migrate particles: x_k^i = x_k^i + ∆λ · dx_k^i/dλ\n",
    " 14      endfor\n",
    " 15      Re-evaluate x̄_k using the updated particles x_k^i\n",
    " 16    endfor\n",
    " 17    Apply UKF/EKF update:\n",
    "         (m_{k|k-1}, P_{k|k-1}) → (m_{k|k}, P_{k|k})\n",
    " 18    Estimate x̂_k from the particles x_k^i using P_{k|k}\n",
    " 19    Optional: redraw particles x_k^i ~ N(x̂_k, P_{k|k})\n",
    " 20  endfor\n",
    "```\n",
    "\n",
    "## References\n",
    "\n",
    "- **Ding & Coates (2012)**: \"Implementation of the Daum-Huang Exact-Flow Particle Filter\", IEEE SSP\n",
    "- **MATLAB Code**: `PFPF/particle_flow/DH_ExactFlow_Filter.m`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import acoustic model functions\n",
    "import sys\n",
    "sys.path.append('Acoustic')\n",
    "from acoustic_function import (\n",
    "    initialize_acoustic_model,\n",
    "    state_transition,\n",
    "    observation_model,\n",
    "    compute_observation_jacobian,\n",
    "    simulate_trajectory\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Acoustic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize acoustic model with default parameters (4 targets, 25 sensors)\n",
    "model_params = initialize_acoustic_model(n_targets=4)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Targets: {model_params['n_targets']}\")\n",
    "print(f\"  Sensors: {model_params['n_sensors']} (5×5 grid)\")\n",
    "print(f\"  State dimension: {model_params['state_dim']}\")\n",
    "print(f\"  Surveillance area: {model_params['sim_area_size']}m × {model_params['sim_area_size']}m\")\n",
    "print(f\"\\nAcoustic Parameters:\")\n",
    "print(f\"  Amplitude (Ψ): {model_params['amplitude'].numpy()}\")\n",
    "print(f\"  Measurement noise std: {model_params['measurement_noise_std']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDH Filter Functions\n",
    "\n",
    "Each function below corresponds to specific lines in Algorithm 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1: Compute Lambda Steps\n",
    "\n",
    "**Purpose**: Compute exponentially spaced lambda steps for particle flow.\n",
    "\n",
    "**Algorithm**: Pre-processing (before Algorithm 1)\n",
    "\n",
    "**Equations**:\n",
    "- Step sizes: $\\epsilon_j = \\epsilon_1 \\cdot q^{j-1}$ for $j = 1, ..., N_\\lambda$\n",
    "- Constraint: $\\sum_{j=1}^{N_\\lambda} \\epsilon_j = 1$\n",
    "- Solution: $\\epsilon_1 = \\frac{1-q}{1-q^{N_\\lambda}}$ where $q > 1$ (typically $q = 1.2$)\n",
    "- Lambda values: $\\lambda_j = \\sum_{i=1}^{j} \\epsilon_i$\n",
    "\n",
    "**MATLAB**: Uses exponential spacing in `DH_ExactFlow_Filter.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda_steps(n_lambda, lambda_ratio):\n",
    "    \"\"\"\n",
    "    Compute exponentially spaced lambda steps.\n",
    "    \n",
    "    Args:\n",
    "        n_lambda: Number of lambda steps (typically 20)\n",
    "        lambda_ratio: Ratio for exponential spacing (typically 1.2)\n",
    "    \n",
    "    Returns:\n",
    "        lambda_steps: Step sizes ε_j, shape (n_lambda,)\n",
    "        lambda_values: Cumulative lambda values λ_j, shape (n_lambda,)\n",
    "    \"\"\"\n",
    "    q = lambda_ratio\n",
    "    n = n_lambda\n",
    "    \n",
    "    # Initial step size: ε_1 = (1-q)/(1-q^n)\n",
    "    epsilon_1 = (1 - q) / (1 - q**n)\n",
    "    \n",
    "    # Step sizes: ε_j = ε_1 * q^(j-1) for j=1,...,n\n",
    "    step_sizes = [epsilon_1 * (q**j) for j in range(n)]\n",
    "    lambda_steps = tf.constant(step_sizes, dtype=tf.float32)\n",
    "    \n",
    "    # Cumulative lambda values: λ_j = Σ_{i=1}^j ε_i\n",
    "    lambda_values = tf.cumsum(lambda_steps)\n",
    "    \n",
    "    print(f\"Lambda configuration:\")\n",
    "    print(f\"  Number of steps: {n_lambda}\")\n",
    "    print(f\"  Ratio (q): {lambda_ratio}\")\n",
    "    print(f\"  First 5 step sizes: {lambda_steps[:5].numpy()}\")\n",
    "    print(f\"  Last 5 lambda values: {lambda_values[-5:].numpy()}\")\n",
    "    print(f\"  Sum of steps: {tf.reduce_sum(lambda_steps).numpy():.6f}\")\n",
    "    \n",
    "    return lambda_steps, lambda_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 2: Initialize Particles\n",
    "\n",
    "**Algorithm Lines 1-2**\n",
    "\n",
    "**Purpose**: Draw initial particles from prior distribution.\n",
    "\n",
    "**Equations**:\n",
    "- Draw: $x_0^{(i)} \\sim \\mathcal{N}(x_0, P_0)$ for $i = 1, ..., N$\n",
    "- Initial mean: $x_0$\n",
    "- Initial covariance: $P_0 = \\text{diag}(\\sigma_0^2)$\n",
    "\n",
    "**MATLAB**: `DH_ExactFlow_Filter.m` lines 21-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_particles(model_params, n_particle):\n",
    "    \"\"\"\n",
    "    Initialize particles from Gaussian prior.\n",
    "    \n",
    "    Algorithm Lines 1-2:\n",
    "      1  Draw {x_0^i}_{i=1}^N from the prior p(x_0)\n",
    "      2  Set x̂_0 and m_0 as the mean; P_0 as the covariance matrix\n",
    "    \n",
    "    Args:\n",
    "        model_params: Dictionary from initialize_acoustic_model()\n",
    "        n_particle: Number of particles\n",
    "    \n",
    "    Returns:\n",
    "        particles: Initial particles, shape (state_dim, n_particle)\n",
    "        P0: Initial covariance, shape (state_dim, state_dim)\n",
    "    \"\"\"\n",
    "    state_dim = model_params['state_dim']\n",
    "    x0 = model_params['x0_initial_target_states']  # (state_dim, 1)\n",
    "    \n",
    "    # Initial uncertainty (from paper)\n",
    "    # Per target: [σ_x, σ_y, σ_vx, σ_vy] = [2.0, 2.0, 0.5, 0.5]\n",
    "    sigma0_single = tf.constant([2.0, 2.0, 0.5, 0.5], dtype=tf.float32)\n",
    "    sigma0 = tf.tile(sigma0_single, [model_params['n_targets']])\n",
    "    \n",
    "    # Line 2: P_0 = diag(σ_0^2)\n",
    "    P0 = tf.linalg.diag(tf.square(sigma0))\n",
    "    \n",
    "    # Line 1: Sample particles x_0^i ~ N(x_0, P_0)\n",
    "    noise = tf.random.normal((state_dim, n_particle), dtype=tf.float32)\n",
    "    particles = x0 + tf.expand_dims(sigma0, 1) * noise\n",
    "    \n",
    "    print(f\"\\nInitialized {n_particle} particles\")\n",
    "    print(f\"  State dimension: {state_dim}\")\n",
    "    print(f\"  Initial mean: {x0[:4, 0].numpy()} (first target)\")\n",
    "    print(f\"  Initial std: {sigma0[:4].numpy()} (first target)\")\n",
    "    \n",
    "    return particles, P0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3: Propagate Particles\n",
    "\n",
    "**Algorithm Line 4**\n",
    "\n",
    "**Purpose**: Propagate particles through motion model.\n",
    "\n",
    "**Equation**:\n",
    "$$x_k^{(i)} = \\Phi x_{k-1}^{(i)} + w_k^{(i)}, \\quad w_k^{(i)} \\sim \\mathcal{N}(0, Q)$$\n",
    "\n",
    "where:\n",
    "- $\\Phi$ is the state transition matrix (constant velocity model)\n",
    "- $Q$ is the process noise covariance\n",
    "\n",
    "**MATLAB**: `DH_ExactFlow_Filter.m` line 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_particles(particles, model_params):\n",
    "    \"\"\"\n",
    "    Propagate particles through motion model.\n",
    "    \n",
    "    Algorithm Line 4:\n",
    "      4  Propagate particles x_{k-1}^i = f_k(x_{k-1}^i) + v_k\n",
    "    \n",
    "    Equation:\n",
    "      x_k = Φ * x_{k-1} + w_k,  where w_k ~ N(0, Q)\n",
    "    \n",
    "    Args:\n",
    "        particles: Current particles, shape (state_dim, n_particle)\n",
    "        model_params: Dictionary with 'Phi' and 'Q'\n",
    "    \n",
    "    Returns:\n",
    "        particles_pred: Predicted particles, shape (state_dim, n_particle)\n",
    "    \"\"\"\n",
    "    state_dim = model_params['state_dim']\n",
    "    Phi = model_params['Phi']  # State transition matrix\n",
    "    Q = model_params['Q']      # Process noise covariance\n",
    "    n_particle = tf.shape(particles)[1]\n",
    "    \n",
    "    # Linear propagation: x_k = Φ * x_{k-1}\n",
    "    particles_pred = tf.matmul(Phi, particles)\n",
    "    \n",
    "    # Add process noise: w_k ~ N(0, Q)\n",
    "    Q_chol = tf.linalg.cholesky(Q)\n",
    "    noise = tf.matmul(Q_chol, tf.random.normal((state_dim, n_particle), dtype=tf.float32))\n",
    "    \n",
    "    return particles_pred + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 4: Estimate Covariance from Particles\n",
    "\n",
    "**Algorithm Lines 6 and 17**\n",
    "\n",
    "**Purpose**: Estimate covariance matrix from particle spread.\n",
    "\n",
    "**Equation**:\n",
    "$$P = \\frac{1}{N-1} \\sum_{i=1}^N (x^{(i)} - \\bar{x})(x^{(i)} - \\bar{x})^T$$\n",
    "\n",
    "where $\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x^{(i)}$\n",
    "\n",
    "**Used for**:\n",
    "- Line 6: $P_{k|k-1}$ (prior covariance) - computed from predicted particles\n",
    "- Line 17: $P_{k|k}$ (posterior covariance) - computed from updated particles\n",
    "\n",
    "**MATLAB**: `cov(particles')` in lines 53, 67, 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_covariance(particles):\n",
    "    \"\"\"\n",
    "    Estimate covariance from particles.\n",
    "    \n",
    "    Algorithm Line 6 (prediction): P_{k|k-1}\n",
    "    Algorithm Line 17 (update): P_{k|k}\n",
    "    \n",
    "    Equation:\n",
    "      P = (1/(N-1)) * Σ (x_i - x̄)(x_i - x̄)^T\n",
    "    \n",
    "    Args:\n",
    "        particles: Particles, shape (state_dim, n_particle)\n",
    "    \n",
    "    Returns:\n",
    "        P: Covariance matrix, shape (state_dim, state_dim)\n",
    "    \"\"\"\n",
    "    # Compute mean\n",
    "    mean = tf.reduce_mean(particles, axis=1, keepdims=True)\n",
    "    \n",
    "    # Center particles\n",
    "    centered = particles - mean\n",
    "    \n",
    "    # Covariance: P = (1/(N-1)) * centered @ centered^T\n",
    "    n_particles = tf.cast(tf.shape(particles)[1], tf.float32)\n",
    "    P = tf.matmul(centered, tf.transpose(centered)) / (n_particles - 1.0)\n",
    "    \n",
    "    # Add small regularization for numerical stability\n",
    "    P = P + 1e-6 * tf.eye(tf.shape(P)[0], dtype=tf.float32)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 5: Compute Flow Parameters A and b\n",
    "\n",
    "**Algorithm Line 10**\n",
    "\n",
    "**Purpose**: Compute flow matrix $A(\\lambda)$ and flow vector $b(\\lambda)$ for particle flow.\n",
    "\n",
    "**Equations** (from Ding & Coates 2012, Equations 8 and 9):\n",
    "\n",
    "$$A(\\lambda) = -\\frac{1}{2} P H^T (\\lambda H P H^T + R)^{-1} H$$\n",
    "\n",
    "$$b(\\lambda) = (I + 2\\lambda A)[(I + \\lambda A) P H^T R^{-1} (z - e) + A\\bar{x}]$$\n",
    "\n",
    "where:\n",
    "- $H = \\frac{\\partial h}{\\partial x}|_{\\bar{x}}$ is the observation Jacobian\n",
    "- $e = h(\\bar{x}) - H\\bar{x}$ is the linearization residual\n",
    "- $z$ is the current measurement\n",
    "- $P$ is the covariance (should be $P_{k|k-1}$)\n",
    "- $R$ is the measurement noise covariance\n",
    "\n",
    "**MATLAB**: `calculateSlope()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flow_parameters(x, x_bar, P, measurement, lam, model_params, use_local=False):\n",
    "    \"\"\"\n",
    "    Compute flow parameters A and b for particle x.\n",
    "    \n",
    "    Algorithm Line 10:\n",
    "      10  Calculate A and b from (8) and (9) using P_{k|k-1}, x̄ and H_x\n",
    "    \n",
    "    Equations:\n",
    "      A(λ) = -1/2 * P * H^T * (λ*H*P*H^T + R)^{-1} * H\n",
    "      b(λ) = (I + 2λA) * [(I + λA) * P*H^T*R^{-1}*(z-e) + A*x̄]\n",
    "    \n",
    "    Args:\n",
    "        x: Particle position (state_dim, 1) - used for linearization\n",
    "        x_bar: Mean trajectory (state_dim, 1) - used in b computation\n",
    "        P: Covariance (state_dim, state_dim) - should be P_{k|k-1}\n",
    "        measurement: Current measurement z, shape (n_sensor, 1)\n",
    "        lam: Current lambda value (scalar)\n",
    "        model_params: Dictionary with observation model\n",
    "        use_local: If True, linearize at x (local); if False, linearize at x_bar (global)\n",
    "    \n",
    "    Returns:\n",
    "        A: Flow matrix, shape (state_dim, state_dim)\n",
    "        b: Flow vector, shape (state_dim,)\n",
    "    \"\"\"\n",
    "    state_dim = tf.shape(P)[0]\n",
    "    R = model_params['R']\n",
    "    \n",
    "    # Algorithm Line 9: Calculate H_x by linearizing at x̄_k (or x_i for local)\n",
    "    linearization_point = x if use_local else x_bar\n",
    "    H = compute_observation_jacobian(linearization_point, model_params)\n",
    "    \n",
    "    # Compute h(x̄) and linearization residual: e = h(x̄) - H*x̄\n",
    "    h_x_bar = observation_model(x_bar, model_params)\n",
    "    h_x_bar = tf.squeeze(h_x_bar, axis=1)  # (n_sensor,)\n",
    "    e = h_x_bar - tf.linalg.matvec(H, tf.squeeze(x_bar, axis=1))\n",
    "    \n",
    "    # Compute H*P*H^T\n",
    "    HPHt = tf.matmul(tf.matmul(H, P), tf.transpose(H))\n",
    "    \n",
    "    # Innovation covariance: S = λ*H*P*H^T + R\n",
    "    S = lam * HPHt + R\n",
    "    S_inv = tf.linalg.inv(S)\n",
    "    \n",
    "    # Compute P*H^T\n",
    "    PHt = tf.matmul(P, tf.transpose(H))\n",
    "    \n",
    "    # Equation (8): Flow matrix A = -0.5 * P*H^T * S^{-1} * H\n",
    "    A = -0.5 * tf.matmul(tf.matmul(PHt, S_inv), H)\n",
    "    \n",
    "    # Innovation: z - e\n",
    "    innovation = tf.squeeze(measurement, axis=1) - e\n",
    "    \n",
    "    # Compute R^{-1}*(z - e)\n",
    "    R_inv = tf.linalg.inv(R)\n",
    "    R_inv_innov = tf.linalg.matvec(R_inv, innovation)\n",
    "    \n",
    "    # Identity matrix\n",
    "    I = tf.eye(state_dim, dtype=tf.float32)\n",
    "    \n",
    "    # (I + λA) and (I + 2λA)\n",
    "    I_plus_lam_A = I + lam * A\n",
    "    I_plus_2lam_A = I + 2 * lam * A\n",
    "    \n",
    "    # Equation (9): Flow vector b\n",
    "    # First term: (I + λA) * P*H^T * R^{-1}*(z - e)\n",
    "    term1 = tf.linalg.matvec(tf.matmul(I_plus_lam_A, PHt), R_inv_innov)\n",
    "    # Second term: A * x̄\n",
    "    term2 = tf.linalg.matvec(A, tf.squeeze(x_bar, axis=1))\n",
    "    # Combined: b = (I + 2λA) * [term1 + term2]\n",
    "    b = tf.linalg.matvec(I_plus_2lam_A, term1 + term2)\n",
    "    \n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 6: Particle Flow\n",
    "\n",
    "**Algorithm Lines 7-16**\n",
    "\n",
    "**Purpose**: Migrate particles from prior to posterior using exact flow.\n",
    "\n",
    "**Flow ODE** (Equation 7):\n",
    "$$\\frac{dx}{d\\lambda} = A(\\lambda) x + b(\\lambda)$$\n",
    "\n",
    "**Numerical integration** (Euler method):\n",
    "$$x^{(j+1)} = x^{(j)} + \\epsilon_j [A(\\lambda_j) x^{(j)} + b(\\lambda_j)]$$\n",
    "\n",
    "where:\n",
    "- $\\epsilon_j$ is the step size at lambda step $j$\n",
    "- $\\lambda_j$ is the cumulative lambda value\n",
    "- Integration from $\\lambda = 0$ (prior) to $\\lambda = 1$ (posterior)\n",
    "\n",
    "**MATLAB**: `DH_ExactFlow_Filter.m` lines 78-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_flow(particles, measurement, P_pred, lambda_steps, lambda_values, \n",
    "                  model_params, use_local=False):\n",
    "    \"\"\"\n",
    "    Migrate particles from prior to posterior using exact flow.\n",
    "    \n",
    "    Algorithm Lines 7-16:\n",
    "      7  for j = 1, ..., N_λ do\n",
    "      8    Set λ = j∆λ\n",
    "      9    Calculate H_x by linearizing γ_k() at x̄_k\n",
    "     10    Calculate A and b from (8) and (9)\n",
    "     11    for i = 1, ..., N do\n",
    "     12      Evaluate dx_k^i/dλ for each particle from (7)\n",
    "     13      Migrate particles: x_k^i = x_k^i + ∆λ · dx_k^i/dλ\n",
    "     14    endfor\n",
    "     15    Re-evaluate x̄_k using the updated particles x_k^i\n",
    "     16  endfor\n",
    "    \n",
    "    Flow Equation (7):\n",
    "      dx/dλ = A(λ) * x + b(λ)\n",
    "    \n",
    "    Euler Update:\n",
    "      x = x + ε_j * [A(λ_j) * x + b(λ_j)]\n",
    "    \n",
    "    Args:\n",
    "        particles: Predicted particles, shape (state_dim, n_particle)\n",
    "        measurement: Current measurement, shape (n_sensor, 1)\n",
    "        P_pred: Prior covariance P_{k|k-1}, shape (state_dim, state_dim)\n",
    "        lambda_steps: Step sizes ε_j, shape (n_lambda,)\n",
    "        lambda_values: Cumulative lambda values λ_j, shape (n_lambda,)\n",
    "        model_params: Dictionary with observation model\n",
    "        use_local: If True, use local linearization (Algorithm 2)\n",
    "                   If False, use global linearization (Algorithm 1)\n",
    "    \n",
    "    Returns:\n",
    "        particles_flowed: Updated particles, shape (state_dim, n_particle)\n",
    "    \"\"\"\n",
    "    # Initialize flow\n",
    "    eta = tf.identity(particles)  # Current particle positions\n",
    "    n_particle = tf.shape(particles)[1]\n",
    "    n_lambda = len(lambda_steps)\n",
    "    \n",
    "    # Algorithm Line 7: for j = 1, ..., N_λ do\n",
    "    for j in range(n_lambda):\n",
    "        # Algorithm Line 8: Set λ = j∆λ\n",
    "        epsilon_j = lambda_steps[j]   # Step size\n",
    "        lambda_j = lambda_values[j]   # Current lambda value\n",
    "        \n",
    "        # Algorithm Line 5 & 15: Calculate/re-evaluate mean x̄_k\n",
    "        eta_bar = tf.reduce_mean(eta, axis=1, keepdims=True)\n",
    "        \n",
    "        if use_local:\n",
    "            # Modified Algorithm 2: Local linearization at each particle\n",
    "            # Algorithm Line 11: for i = 1, ..., N do\n",
    "            slopes = []\n",
    "            for i in range(n_particle):\n",
    "                x_i = tf.expand_dims(eta[:, i], 1)  # (state_dim, 1)\n",
    "                \n",
    "                # Lines 9-10: Compute A_i, b_i for THIS particle\n",
    "                A_i, b_i = compute_flow_parameters(x_i, eta_bar, P_pred, measurement, \n",
    "                                                   lambda_j, model_params, use_local=True)\n",
    "                \n",
    "                # Line 12: Evaluate dx^i/dλ = A_i * x^i + b_i\n",
    "                slope_i = tf.linalg.matvec(A_i, tf.squeeze(x_i)) + b_i\n",
    "                slopes.append(slope_i)\n",
    "            \n",
    "            slopes = tf.stack(slopes, axis=1)  # (state_dim, n_particle)\n",
    "        else:\n",
    "            # Original Algorithm 1: Global linearization at mean\n",
    "            # Lines 9-10: Compute A, b ONCE at mean x̄_k\n",
    "            A, b = compute_flow_parameters(eta_bar, eta_bar, P_pred, measurement,\n",
    "                                          lambda_j, model_params, use_local=False)\n",
    "            \n",
    "            # Line 12: Evaluate dx^i/dλ = A * x^i + b for ALL particles\n",
    "            slopes = tf.matmul(A, eta) + tf.expand_dims(b, 1)\n",
    "        \n",
    "        # Algorithm Line 13: Migrate particles x^i = x^i + ∆λ · (dx^i/dλ)\n",
    "        eta = eta + epsilon_j * slopes\n",
    "    \n",
    "    return eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 7: EDH Filter Step\n",
    "\n",
    "**Algorithm Lines 4-18**\n",
    "\n",
    "**Purpose**: Perform one complete filter step (prediction + update).\n",
    "\n",
    "**Steps**:\n",
    "1. **Line 4**: Propagate particles (prediction)\n",
    "2. **Line 6**: Compute $P_{k|k-1}$ (prior covariance)\n",
    "3. **Lines 7-16**: Particle flow using $P_{k|k-1}$\n",
    "4. **Line 17**: Compute $P_{k|k}$ (posterior covariance)\n",
    "5. **Line 18**: Estimate state from particles\n",
    "\n",
    "**MATLAB**: `DH_ExactFlow_Filter.m` main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edh_filter_step(particles, measurement, lambda_steps, lambda_values, \n",
    "                    model_params, use_local=False):\n",
    "    \"\"\"\n",
    "    Perform one EDH filter step.\n",
    "    \n",
    "    Algorithm Lines 4-18:\n",
    "      4  Propagate particles\n",
    "      5  Calculate mean\n",
    "      6  Apply UKF/EKF prediction → P_{k|k-1}\n",
    "      7-16  Particle flow (using P_{k|k-1})\n",
    "      17  Apply UKF/EKF update → P_{k|k}\n",
    "      18  Estimate x̂_k\n",
    "    \n",
    "    Args:\n",
    "        particles: Current particles, shape (state_dim, n_particle)\n",
    "        measurement: Current measurement, shape (n_sensor, 1)\n",
    "        lambda_steps: Step sizes, shape (n_lambda,)\n",
    "        lambda_values: Lambda values, shape (n_lambda,)\n",
    "        model_params: Dictionary with model parameters\n",
    "        use_local: If True, use local linearization\n",
    "    \n",
    "    Returns:\n",
    "        particles_updated: Updated particles, shape (state_dim, n_particle)\n",
    "        mean_estimate: State estimate, shape (state_dim,)\n",
    "        P_updated: Posterior covariance P_{k|k}, shape (state_dim, state_dim)\n",
    "    \"\"\"\n",
    "    # Algorithm Line 4: PREDICTION - Propagate particles\n",
    "    particles_pred = propagate_particles(particles, model_params)\n",
    "    \n",
    "    # Algorithm Line 6: Compute P_{k|k-1} (prior/predicted covariance)\n",
    "    # This is the covariance AFTER prediction, BEFORE update\n",
    "    P_pred = estimate_covariance(particles_pred)\n",
    "    \n",
    "    # Algorithm Lines 7-16: UPDATE - Particle flow from prior to posterior\n",
    "    # Uses P_{k|k-1} throughout the flow\n",
    "    particles_flowed = particle_flow(particles_pred, measurement, P_pred, \n",
    "                                     lambda_steps, lambda_values, \n",
    "                                     model_params, use_local)\n",
    "    \n",
    "    # Algorithm Line 17: Compute P_{k|k} (posterior/updated covariance)\n",
    "    # This is the covariance AFTER incorporating measurement\n",
    "    P_updated = estimate_covariance(particles_flowed)\n",
    "    \n",
    "    # Algorithm Line 18: ESTIMATE - Compute state estimate\n",
    "    mean_estimate = tf.reduce_mean(particles_flowed, axis=1)\n",
    "    \n",
    "    return particles_flowed, mean_estimate, P_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 8: Run EDH Filter\n",
    "\n",
    "**Algorithm Line 3 (main loop)**\n",
    "\n",
    "**Purpose**: Run EDH filter on full measurement sequence.\n",
    "\n",
    "**MATLAB**: `DH_ExactFlow_Filter.m` main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_edh_filter(measurements, model_params, n_particle=100, n_lambda=20, \n",
    "                   lambda_ratio=1.2, use_local=False):\n",
    "    \"\"\"\n",
    "    Run EDH filter on measurement sequence.\n",
    "    \n",
    "    Algorithm Main Loop:\n",
    "      1-2  Initialize particles and covariance\n",
    "      3    for k = 1 to T do\n",
    "             [Lines 4-19: filter step]\n",
    "           endfor\n",
    "    \n",
    "    Args:\n",
    "        measurements: Measurements, shape (n_sensor, T)\n",
    "        model_params: Dictionary with model parameters\n",
    "        n_particle: Number of particles\n",
    "        n_lambda: Number of lambda steps\n",
    "        lambda_ratio: Exponential spacing ratio\n",
    "        use_local: If True, use local linearization (Algorithm 2)\n",
    "                   If False, use global linearization (Algorithm 1)\n",
    "    \n",
    "    Returns:\n",
    "        estimates: State estimates, shape (state_dim, T)\n",
    "        particles_all: All particles, shape (state_dim, n_particle, T)\n",
    "        covariances_all: All covariances P_{k|k}, shape (state_dim, state_dim, T)\n",
    "    \"\"\"\n",
    "    T = tf.shape(measurements)[1].numpy()\n",
    "    \n",
    "    print(f\"\\nRunning EDH Filter:\")\n",
    "    print(f\"  Particles: {n_particle}\")\n",
    "    print(f\"  Lambda steps: {n_lambda}\")\n",
    "    print(f\"  Lambda ratio: {lambda_ratio}\")\n",
    "    print(f\"  Linearization: {'Local (Algorithm 2)' if use_local else 'Global (Algorithm 1)'}\")\n",
    "    print(f\"  Time steps: {T}\")\n",
    "    \n",
    "    # Pre-compute lambda steps\n",
    "    lambda_steps, lambda_values = compute_lambda_steps(n_lambda, lambda_ratio)\n",
    "    \n",
    "    # Algorithm Lines 1-2: Initialize particles and covariance\n",
    "    particles, P = initialize_particles(model_params, n_particle)\n",
    "    \n",
    "    # Storage\n",
    "    estimates_list = []\n",
    "    particles_list = []\n",
    "    covariances_list = []\n",
    "    \n",
    "    # Algorithm Line 3: for k = 1 to T do\n",
    "    print(\"\\nProcessing time steps...\")\n",
    "    for t in range(T):\n",
    "        if (t + 1) % 10 == 0:\n",
    "            print(f\"  Step {t+1}/{T}\")\n",
    "        \n",
    "        z_t = tf.expand_dims(measurements[:, t], 1)  # (n_sensor, 1)\n",
    "        \n",
    "        # Filter step - includes Lines 4-18\n",
    "        particles, mean_estimate, P = edh_filter_step(\n",
    "            particles, z_t, lambda_steps, lambda_values, model_params, use_local\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        estimates_list.append(tf.expand_dims(mean_estimate, 1))\n",
    "        particles_list.append(tf.expand_dims(particles, 2))\n",
    "        covariances_list.append(tf.expand_dims(P, 2))\n",
    "    \n",
    "    # Concatenate results\n",
    "    estimates = tf.concat(estimates_list, axis=1)\n",
    "    particles_all = tf.concat(particles_list, axis=2)\n",
    "    covariances_all = tf.concat(covariances_list, axis=2)\n",
    "    \n",
    "    print(\"\\nEDH filter completed successfully!\")\n",
    "    print(f\"  Estimates shape: {estimates.shape}\")\n",
    "    print(f\"  Particles shape: {particles_all.shape}\")\n",
    "    print(f\"  Covariances shape: {covariances_all.shape}\")\n",
    "    \n",
    "    return estimates, particles_all, covariances_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground truth trajectory and measurements\n",
    "T = 30  # Number of time steps\n",
    "\n",
    "print(f\"Generating ground truth trajectory ({T} time steps)...\")\n",
    "ground_truth, measurements = simulate_trajectory(model_params, T, keep_in_bounds=True)\n",
    "\n",
    "print(f\"Ground truth shape: {ground_truth.shape}\")\n",
    "print(f\"Measurements shape: {measurements.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run EDH Filter\n",
    "\n",
    "Now we run the filter using the function-based implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EDH filter with global linearization (Algorithm 1)\n",
    "edh_estimates, edh_particles, edh_covariances = run_edh_filter(\n",
    "    measurements=measurements,\n",
    "    model_params=model_params,\n",
    "    n_particle=100,\n",
    "    n_lambda=20,\n",
    "    lambda_ratio=1.2,\n",
    "    use_local=False  # Algorithm 1: Global linearization\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_position_error(estimates, ground_truth, n_targets):\n",
    "    \"\"\"Compute position error for each target.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(n_targets):\n",
    "        x_idx = i * 4\n",
    "        y_idx = i * 4 + 1\n",
    "        \n",
    "        x_err = estimates[x_idx, :] - ground_truth[x_idx, :]\n",
    "        y_err = estimates[y_idx, :] - ground_truth[y_idx, :]\n",
    "        \n",
    "        error = tf.sqrt(x_err**2 + y_err**2)\n",
    "        errors.append(error)\n",
    "    \n",
    "    errors = tf.stack(errors, axis=0)  # (n_targets, T)\n",
    "    mean_error = tf.reduce_mean(errors, axis=0)  # (T,)\n",
    "    \n",
    "    return errors, mean_error\n",
    "\n",
    "# Compute errors\n",
    "edh_errors, edh_mean_error = compute_position_error(\n",
    "    edh_estimates, ground_truth, model_params['n_targets']\n",
    ")\n",
    "\n",
    "# Overall RMSE\n",
    "rmse = tf.sqrt(tf.reduce_mean((edh_estimates - ground_truth)**2))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EDH Filter Performance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Overall RMSE: {rmse.numpy():.4f} m\")\n",
    "print(f\"Mean position error (final): {edh_mean_error[-1].numpy():.4f} m\")\n",
    "print(f\"Mean position error (average): {tf.reduce_mean(edh_mean_error).numpy():.4f} m\")\n",
    "print(\"\\nPer-target average errors:\")\n",
    "for i in range(model_params['n_targets']):\n",
    "    avg_err = tf.reduce_mean(edh_errors[i]).numpy()\n",
    "    print(f\"  Target {i+1}: {avg_err:.4f} m\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot estimated trajectories\n",
    "fig, ax = plt.subplots(figsize=(11, 10))\n",
    "\n",
    "# Plot sensors\n",
    "sensors = model_params['sensor_positions'].numpy()\n",
    "ax.scatter(sensors[:, 0], sensors[:, 1], \n",
    "          c='blue', marker='o', s=100, label='Sensors', alpha=0.6, zorder=5)\n",
    "\n",
    "colors = ['red', 'green', 'purple', 'orange']\n",
    "gt = ground_truth.numpy()\n",
    "est = edh_estimates.numpy()\n",
    "\n",
    "for i in range(model_params['n_targets']):\n",
    "    x_idx = i * 4\n",
    "    y_idx = i * 4 + 1\n",
    "    \n",
    "    # Ground truth\n",
    "    x_true = gt[x_idx, :]\n",
    "    y_true = gt[y_idx, :]\n",
    "    ax.plot(x_true, y_true, '-', color=colors[i], linewidth=2.5,\n",
    "           label=f'Target {i+1} (True)', alpha=0.7)\n",
    "    \n",
    "    # Estimates\n",
    "    x_est = est[x_idx, :]\n",
    "    y_est = est[y_idx, :]\n",
    "    ax.plot(x_est, y_est, '--', color=colors[i], linewidth=2.5,\n",
    "           label=f'Target {i+1} (EDH)', alpha=0.9, linestyle='dashed')\n",
    "    \n",
    "    # Mark start\n",
    "    ax.plot(x_true[0], y_true[0], 'o', color=colors[i], \n",
    "           markersize=12, markeredgecolor='black', markeredgewidth=2)\n",
    "\n",
    "ax.set_xlabel('X (m)', fontsize=14)\n",
    "ax.set_ylabel('Y (m)', fontsize=14)\n",
    "ax.set_title('EDH Filter: True vs Estimated Trajectories', fontsize=16, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim([0, model_params['sim_area_size']])\n",
    "ax.set_ylim([0, model_params['sim_area_size']])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary: Function-to-Algorithm Mapping\n",
    "\n",
    "| Function | Algorithm Lines | Purpose |\n",
    "|----------|----------------|----------|\n",
    "| `compute_lambda_steps()` | Pre-processing | Exponential spacing for lambda |\n",
    "| `initialize_particles()` | 1-2 | Draw particles from prior |\n",
    "| `propagate_particles()` | 4 | Motion model prediction |\n",
    "| `estimate_covariance()` | 6, 17 | Compute P_{k\\|k-1} and P_{k\\|k} |\n",
    "| `compute_flow_parameters()` | 9-10 | Compute A(λ) and b(λ) |\n",
    "| `particle_flow()` | 7-16 | Migrate particles using flow |\n",
    "| `edh_filter_step()` | 4-18 | One complete filter iteration |\n",
    "| `run_edh_filter()` | 1-20 | Full filter on sequence |\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Dual Covariance Computation**:\n",
    "   - `estimate_covariance(particles_pred)` → P_{k|k-1} (Line 6)\n",
    "   - `estimate_covariance(particles_flowed)` → P_{k|k} (Line 17)\n",
    "\n",
    "2. **Flow Uses Prior Covariance**:\n",
    "   - `particle_flow()` receives P_{k|k-1} as input\n",
    "   - This covariance is used throughout the lambda loop\n",
    "\n",
    "3. **Local vs Global**:\n",
    "   - `use_local=False`: Algorithm 1 (global linearization at mean)\n",
    "   - `use_local=True`: Algorithm 2 (local linearization at each particle)\n",
    "\n",
    "4. **Verification**:\n",
    "   - Each function has clear docstring linking to algorithm lines\n",
    "   - Mathematical equations are included in comments\n",
    "   - Easy to trace and verify against the paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
